{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import re\n",
    "import torch\n",
    "import commons\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from text.symbols import symbols\n",
    "from data_utils import TextMelLoader, TextMelCollate\n",
    "import re\n",
    "from text import _clean_text\n",
    "hps = utils.get_hparams_from_file(\"./configs/base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text import text_to_sequence, cmudict\n",
    "hps = utils.get_hparams_from_file(\"./configs/base.json\")\n",
    "cmu_dict = cmudict.CMUDict(hps.data.cmudict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, DistilBertConfig\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPhoneMelLoader(TextMelLoader):\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audiopath, sent = self.audiopaths_and_text[index]\n",
    "        phones, mel = self.get_mel_text_pair((audiopath, sent))\n",
    "        \n",
    "        clean_sent = _clean_text(sent, ['english_cleaners'])\n",
    "        wordpieces = tokenizer.encode(clean_sent, add_special_tokens=True)\n",
    "        wordpieces = torch.IntTensor(wordpieces)\n",
    "\n",
    "        words = clean_sent.split(\" \")\n",
    "        wordpiece_attn = torch.zeros((len(wordpieces), len(words)))\n",
    "        phone_attn = torch.zeros((len(phones), len(words)))\n",
    "\n",
    "        wp_idx = 0\n",
    "        ph_idx = 0\n",
    "        wordpieces_ = wordpieces.numpy()\n",
    "        phones_ = phones.numpy()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            phs = text_to_sequence(word, ['english_cleaners'], cmu_dict)\n",
    "            wps = tokenizer.encode(word, add_special_tokens=False)\n",
    "\n",
    "            while np.any(wordpieces_[wp_idx:wp_idx+len(wps)] - wps):\n",
    "                if wp_idx + len(wps) >= len(wordpieces_):\n",
    "                    break\n",
    "                wp_idx += 1\n",
    "            if not np.any(wordpieces_[wp_idx:wp_idx+len(wps)] - wps):\n",
    "                wordpiece_attn[wp_idx:wp_idx +len(wps), i] = 1\n",
    "            \n",
    "            while np.any(phones_[ph_idx:ph_idx+len(phs)] - phs):\n",
    "                if ph_idx + len(phs) >= len(phones_):\n",
    "                    break\n",
    "                ph_idx += 1\n",
    "            if not np.any(phones_[ph_idx:ph_idx+len(phs)] - phs):\n",
    "                phone_attn[ph_idx:ph_idx + len(phs), i] = 1\n",
    "                if ph_idx+len(phs) < len(phones_) and phones_[ph_idx+len(phs)] == 11:\n",
    "                    phone_attn[ph_idx+len(phs), i] = 1\n",
    "                    ph_idx += 1 \n",
    "                    \n",
    "        assert torch.all(wordpiece_attn.sum(dim=0))\n",
    "        assert torch.all(phone_attn.sum(dim=0))\n",
    "        \n",
    "        return wordpieces, phones, mel, wordpiece_attn, phone_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPhoneMelCollate(TextMelCollate):\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        text_lengths = torch.LongTensor([len(x[0]) for x in batch])\n",
    "        max_text_len = max(text_lengths)\n",
    "        text_padded = torch.LongTensor(len(batch), max_text_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(batch)):\n",
    "            text = batch[i][0]\n",
    "            text_padded[i, :text.size(0)] = text\n",
    "\n",
    "        phone_lengths = torch.LongTensor([len(x[1]) for x in batch])\n",
    "        max_phone_len = max(phone_lengths)\n",
    "        phones_padded = torch.LongTensor(len(batch), max_phone_len)\n",
    "        phones_padded.zero_()\n",
    "        for i in range(len(batch)):\n",
    "            phones = batch[i][1]\n",
    "            phones_padded[i, :phones.size(0)] = phones\n",
    "    \n",
    "        num_mels = batch[0][2].size(0)\n",
    "        max_target_len = max([x[2].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        mel_lengths = torch.LongTensor(len(batch))\n",
    "        for i in range(len(batch)):\n",
    "            mel = batch[i][2]\n",
    "            mel_padded[i, :, :mel.size(1)] = mel\n",
    "            mel_lengths[i] = mel.size(1)\n",
    "            \n",
    "        max_word_count = max([x[3].size(1) for x in batch])\n",
    "        wordpiece_attn_padded = torch.zeros((len(batch), max_text_len, max_word_count))\n",
    "        phone_attn_padded = torch.zeros((len(batch), max_phone_len, max_word_count))\n",
    "        for i in range(len(batch)):\n",
    "            wordpiece_attn_padded[i, :batch[i][3].size(0), :batch[i][3].size(1)] = batch[i][3]\n",
    "            phone_attn_padded[i, :batch[i][4].size(0), :batch[i][4].size(1)] = batch[i][4]\n",
    "        \n",
    "        return text_padded, text_lengths, phones_padded, phone_lengths, mel_padded, mel_lengths, wordpiece_attn_padded, phone_attn_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = WordPhoneMelCollate(1)\n",
    "\n",
    "train_dataset = WordPhoneMelLoader(hps.data.training_files, hps.data)\n",
    "train_loader = DataLoader(train_dataset, num_workers=8, shuffle=False,\n",
    "      batch_size=hps.train.batch_size, pin_memory=True,\n",
    "      drop_last=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WordPhoneMelLoader('filelists/ljs_audio_text_test_filelist.txt', hps.data)\n",
    "test_loader = DataLoader(test_dataset, num_workers=8, shuffle=False,\n",
    "                         batch_size=hps.train.batch_size, pin_memory=True,\n",
    "                         drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [01:10,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "save_dir = 'temp_data/train/'\n",
    "os.mkdir(save_dir)\n",
    "file_bases = ['wp%d.npy', 'wp_len%d.npy', 'ph%d.npy', 'ph_len%d.npy', 'mel_%d.npy', 'mel_len%d.npy', 'wp_attn%d.npy', 'ph_attn%d.npy']\n",
    "for batch_idx, data in tqdm(enumerate(train_loader)):\n",
    "    for item, file_base in zip(data, file_bases):\n",
    "        np.save(os.path.join(save_dir, file_base % batch_idx), item.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:03,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'temp_data/test/'\n",
    "os.mkdir(save_dir)\n",
    "file_bases = ['wp%d.npy', 'wp_len%d.npy', 'ph%d.npy', 'ph_len%d.npy', 'mel_%d.npy', 'mel_len%d.npy', 'wp_attn%d.npy', 'ph_attn%d.npy']\n",
    "for batch_idx, data in tqdm(enumerate(test_loader)):\n",
    "    for item, file_base in zip(data, file_bases):\n",
    "        np.save(os.path.join(save_dir, file_base % batch_idx), item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class disk_loader:\n",
    "    \n",
    "    ITEMS = ['wp', 'wp_len', 'ph', 'ph_len', 'mel_', 'mel_len', 'wp_attn', 'ph_attn']\n",
    "    dummy = 'wp_attn'\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        filenames = os.listdir(path)\n",
    "        self.filenames = [f for f in filenames if self.dummy in f]\n",
    "        random.shuffle(self.filenames)\n",
    "    \n",
    "    def loader(self):\n",
    "        for f in self.filenames:\n",
    "            items = [np.load(os.path.join(self.path, f.replace(self.dummy, item_name))) for item_name in self.ITEMS]\n",
    "            yield items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 101, 1103,  107, ...,    0,    0,    0],\n",
      "       [ 101, 1105,  107, ...,    0,    0,    0],\n",
      "       [ 101,  170, 1748, ...,  119,  102,    0],\n",
      "       ...,\n",
      "       [ 101, 1103, 3137, ...,    0,    0,    0],\n",
      "       [ 101, 1103, 3318, ...,    0,    0,    0],\n",
      "       [ 101, 1598, 5923, ...,    0,    0,    0]]), array([18, 25, 32, 27, 29, 30, 26, 20, 25, 23,  9, 18, 28, 18, 20, 29, 18,\n",
      "       33, 32, 24, 22, 13, 21, 28, 27, 22, 22, 13, 26, 21, 15, 17]), array([[ 91,  73,  11, ...,   0,   0,   0],\n",
      "       [ 73, 119,  90, ...,   0,   0,   0],\n",
      "       [102,  11, 104, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [ 91,  73,  11, ...,   0,   0,   0],\n",
      "       [ 91,  73,  11, ...,   0,   0,   0],\n",
      "       [116,  73, 119, ...,   0,   0,   0]]), array([ 57,  73, 106,  99, 111, 117,  87,  82,  89, 115,  26,  78, 120,\n",
      "        59,  71, 106,  55, 131, 112,  86,  87,  48,  68, 129,  94,  73,\n",
      "        98,  49, 105,  72,  81,  69]), array([[[ -9.737273 ,  -8.349141 ,  -6.771012 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -8.811881 ,  -7.958945 ,  -6.249183 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -8.7317   ,  -6.9163136,  -5.683454 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -9.923061 ,  -9.890175 ,  -9.954345 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -9.833612 ,  -9.940031 , -10.216162 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [-10.063017 ,  -9.804131 ,  -9.814166 , ...,   0.       ,\n",
      "           0.       ,   0.       ]],\n",
      "\n",
      "       [[ -7.6987615,  -7.0188007,  -6.277863 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -7.3092866,  -6.305359 ,  -5.7606916, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -5.9301224,  -5.4450226,  -4.6555266, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -9.563213 ,  -7.3387656,  -6.322083 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -9.263757 ,  -6.750711 ,  -5.8351035, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -9.319494 ,  -6.5168366,  -5.495535 , ...,   0.       ,\n",
      "           0.       ,   0.       ]],\n",
      "\n",
      "       [[ -7.106783 ,  -6.086542 ,  -6.1532936, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.3643827,  -5.8775578,  -5.9062076, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.383252 ,  -6.1248217,  -5.345411 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -9.825865 ,  -7.8994093,  -6.800025 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -8.745479 ,  -6.5235496,  -6.0368366, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -7.6961274,  -5.0294557,  -4.360833 , ...,   0.       ,\n",
      "           0.       ,   0.       ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -6.7366667,  -6.7184935,  -6.617439 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.2389703,  -6.1504803,  -5.848159 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -5.913077 ,  -5.670059 ,  -5.42022  , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -7.64454  ,  -7.56803  ,  -8.369914 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -7.1076255,  -7.1058645,  -7.8150816, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.3907123,  -6.3096185,  -6.7861567, ...,   0.       ,\n",
      "           0.       ,   0.       ]],\n",
      "\n",
      "       [[ -6.6076612,  -7.214467 ,  -5.8328958, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -5.885821 ,  -6.113522 ,  -4.991522 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.136773 ,  -5.474706 ,  -4.611565 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -8.9684925,  -7.391    ,  -5.8628945, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -8.138372 ,  -6.8104377,  -5.383027 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -7.876843 ,  -6.8138056,  -5.393066 , ...,   0.       ,\n",
      "           0.       ,   0.       ]],\n",
      "\n",
      "       [[ -7.44091  ,  -7.528298 ,  -7.955494 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -8.030361 ,  -7.708729 ,  -7.392149 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.770079 ,  -6.790996 ,  -6.7726827, ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        ...,\n",
      "        [ -7.285447 ,  -5.8864627,  -5.030703 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -6.515645 ,  -5.2714186,  -4.390294 , ...,   0.       ,\n",
      "           0.       ,   0.       ],\n",
      "        [ -5.7768455,  -4.484177 ,  -4.083512 , ...,   0.       ,\n",
      "           0.       ,   0.       ]]], dtype=float32), array([403, 496, 687, 670, 725, 725, 686, 498, 561, 707, 145, 493, 828,\n",
      "       375, 400, 800, 295, 807, 855, 520, 515, 294, 439, 801, 751, 416,\n",
      "       569, 317, 659, 486, 476, 434]), array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), array([[[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "dl = disk_loader('temp_data/train/')\n",
    "for i in (dl.loader()):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = WordPhoneMelCollate(1)\n",
    "\n",
    "train_dataset = WordPhoneMelLoader(hps.data.training_files, hps.data)\n",
    "train_loader = DataLoader(train_dataset, num_workers=8, shuffle=False,\n",
    "      batch_size=hps.train.batch_size, pin_memory=True,\n",
    "      drop_last=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = WordPhoneMelLoader('filelists/ljs_audio_text_test_filelist.txt', hps.data)\n",
    "test_loader = DataLoader(test_dataset, num_workers=8, shuffle=False,\n",
    "      batch_size=hps.train.batch_size, pin_memory=True,\n",
    "      drop_last=True, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
