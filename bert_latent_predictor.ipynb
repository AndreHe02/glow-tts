{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import re\n",
    "import torch\n",
    "import commons\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from text.symbols import symbols\n",
    "from data_utils import TextMelLoader, TextMelCollate\n",
    "import re\n",
    "from text import _clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text import text_to_sequence, cmudict\n",
    "hps = utils.get_hparams_from_file(\"./configs/base.json\")\n",
    "cmu_dict = cmudict.CMUDict(hps.data.cmudict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, DistilBertConfig\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPhoneMelLoader(TextMelLoader):\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audiopath, sent = self.audiopaths_and_text[index]\n",
    "        phones, mel = self.get_mel_text_pair((audiopath, sent))\n",
    "        \n",
    "        clean_sent = _clean_text(sent, ['english_cleaners'])\n",
    "        wordpieces = tokenizer.encode(clean_sent, add_special_tokens=True)\n",
    "        wordpieces = torch.IntTensor(wordpieces)\n",
    "\n",
    "        words = clean_sent.split(\" \")\n",
    "        wordpiece_attn = torch.zeros((len(wordpieces), len(words)))\n",
    "        phone_attn = torch.zeros((len(phones), len(words)))\n",
    "\n",
    "        wp_idx = 0\n",
    "        ph_idx = 0\n",
    "        wordpieces_ = wordpieces.numpy()\n",
    "        phones_ = phones.numpy()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            phs = text_to_sequence(word, ['english_cleaners'], cmu_dict)\n",
    "            wps = tokenizer.encode(word, add_special_tokens=False)\n",
    "\n",
    "            while np.any(wordpieces_[wp_idx:wp_idx+len(wps)] - wps):\n",
    "                if wp_idx + len(wps) >= len(wordpieces_):\n",
    "                    break\n",
    "                wp_idx += 1\n",
    "            if not np.any(wordpieces_[wp_idx:wp_idx+len(wps)] - wps):\n",
    "                wordpiece_attn[wp_idx:wp_idx +len(wps), i] = 1\n",
    "            \n",
    "            while np.any(phones_[ph_idx:ph_idx+len(phs)] - phs):\n",
    "                if ph_idx + len(phs) >= len(phones_):\n",
    "                    break\n",
    "                ph_idx += 1\n",
    "            if not np.any(phones_[ph_idx:ph_idx+len(phs)] - phs):\n",
    "                phone_attn[ph_idx:ph_idx + len(phs), i] = 1\n",
    "                if ph_idx+len(phs) < len(phones_) and phones_[ph_idx+len(phs)] == 11:\n",
    "                    phone_attn[ph_idx+len(phs), i] = 1\n",
    "                    ph_idx += 1 \n",
    "                    \n",
    "        assert torch.all(wordpiece_attn.sum(dim=0))\n",
    "        assert torch.all(phone_attn.sum(dim=0))\n",
    "        \n",
    "        return wordpieces, phones, mel, wordpiece_attn, phone_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPhoneMelCollate(TextMelCollate):\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        text_lengths = torch.LongTensor([len(x[0]) for x in batch])\n",
    "        max_text_len = max(text_lengths)\n",
    "        text_padded = torch.LongTensor(len(batch), max_text_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(batch)):\n",
    "            text = batch[i][0]\n",
    "            text_padded[i, :text.size(0)] = text\n",
    "\n",
    "        phone_lengths = torch.LongTensor([len(x[1]) for x in batch])\n",
    "        max_phone_len = max(phone_lengths)\n",
    "        phones_padded = torch.LongTensor(len(batch), max_phone_len)\n",
    "        phones_padded.zero_()\n",
    "        for i in range(len(batch)):\n",
    "            phones = batch[i][1]\n",
    "            phones_padded[i, :phones.size(0)] = phones\n",
    "    \n",
    "        num_mels = batch[0][2].size(0)\n",
    "        max_target_len = max([x[2].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        mel_lengths = torch.LongTensor(len(batch))\n",
    "        for i in range(len(batch)):\n",
    "            mel = batch[i][2]\n",
    "            mel_padded[i, :, :mel.size(1)] = mel\n",
    "            mel_lengths[i] = mel.size(1)\n",
    "            \n",
    "        max_word_count = max([x[3].size(1) for x in batch])\n",
    "        wordpiece_attn_padded = torch.zeros((len(batch), max_text_len, max_word_count))\n",
    "        phone_attn_padded = torch.zeros((len(batch), max_phone_len, max_word_count))\n",
    "        for i in range(len(batch)):\n",
    "            wordpiece_attn_padded[i, :batch[i][3].size(0), :batch[i][3].size(1)] = batch[i][3]\n",
    "            phone_attn_padded[i, :batch[i][4].size(0), :batch[i][4].size(1)] = batch[i][4]\n",
    "        \n",
    "        return text_padded, text_lengths, phones_padded, phone_lengths, mel_padded, mel_lengths, wordpiece_attn_padded, phone_attn_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = WordPhoneMelCollate(1)\n",
    "\n",
    "train_dataset = WordPhoneMelLoader(hps.data.training_files, hps.data)\n",
    "train_loader = DataLoader(train_dataset, num_workers=8, shuffle=False,\n",
    "      batch_size=hps.train.batch_size, pin_memory=True,\n",
    "      drop_last=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = WordPhoneMelLoader('filelists/ljs_audio_text_test_filelist.txt', hps.data)\n",
    "test_loader = DataLoader(test_dataset, num_workers=8, shuffle=False,\n",
    "      batch_size=hps.train.batch_size, pin_memory=True,\n",
    "      drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = utils.get_hparams_from_file(\"./configs/base.json\")\n",
    "checkpoint_path = \"pretrained/pretrained.pth\"\n",
    "\n",
    "model = models.FlowGenerator(\n",
    "    len(symbols) + getattr(hps.data, \"add_blank\", False),\n",
    "    out_channels=hps.data.n_mel_channels,\n",
    "    **hps.model).to(\"cuda\")\n",
    "\n",
    "utils.load_checkpoint(checkpoint_path, model)\n",
    "model.decoder.store_inverse() # do not calcuate jacobians for fast decoding\n",
    "generator = model\n",
    "_ = generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class BertLinearLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.dim = self.bert.config.dim\n",
    "        self.ph_projs = nn.Embedding(len(symbols)+1, self.dim * 80)\n",
    "    \n",
    "    def forward(self, wp, ph, wp_attn, ph_attn, attn):\n",
    "        wp_embed = self.bert(wp)[0]  # [b, #wp, dim=768]\n",
    "        word_embed = torch.einsum('bpd, bpw -> bwd', wp_embed, wp_attn)\n",
    "        wp_per_word = torch.sum(wp_attn, dim=1).unsqueeze(dim=-1)\n",
    "        word_embed = word_embed / torch.maximum(wp_per_word, torch.ones_like(wp_per_word)) # [b, #w, dim]\n",
    "        ph_embed = torch.einsum('bwd, bpw -> bpd', word_embed, ph_attn) # [b, #ph, dim]\n",
    "    \n",
    "        ph_proj = self.ph_projs(ph) # [b, #ph, dim*80]\n",
    "        ph_proj_mats = torch.reshape(ph_proj, (ph_proj.shape[0], ph_proj.shape[1], self.dim, 80))\n",
    "        x = torch.einsum('bpd, bpdl -> blp', ph_embed, ph_proj_mats)\n",
    "        z = torch.matmul(attn.squeeze(1).transpose(1, 2), x.transpose(1, 2)).transpose(1, 2)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(num_epochs, model, opt):\n",
    "    model.train()\n",
    "    #print('Control ', evaluate_control())\n",
    "    log = {'train':[], 'test':[]}\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (wp, wp_len, ph, ph_len, mel, mel_len, wp_attn, ph_attn) in tqdm(enumerate(train_loader)):\n",
    "            with torch.no_grad():\n",
    "                wp, wp_len = wp.cuda(), wp_len.cuda()\n",
    "                ph, ph_len = ph.cuda(), ph_len.cuda()\n",
    "                mel, mel_len = mel.cuda(), mel_len.cuda()\n",
    "                wp_attn, ph_attn = wp_attn.float().cuda(), ph_attn.float().cuda() # [b, #wp, #wrds], [b, #ph, #wrds]\n",
    "\n",
    "                (z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_) = \\\n",
    "                    generator(ph, ph_len, mel, mel_len, gen=False)\n",
    "                \n",
    "            z_bert = model(wp, ph, wp_attn, ph_attn, attn)\n",
    "            #loss = commons.mle_loss(z, z_m+z_bert, z_logs, logdet, z_mask)\n",
    "            loss = commons.mle_loss(z, z_bert, z_logs, logdet, z_mask)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        test_loss = evaluate(model)\n",
    "        print('Train, Test:')\n",
    "        print(train_loss, test_loss)\n",
    "        log['train'].append(train_loss)\n",
    "        log['test'].append(test_loss)\n",
    "    return log\n",
    "    \n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    total_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (wp, wp_len, ph, ph_len, mel, mel_len, wp_attn, ph_attn) in enumerate(test_loader):\n",
    "            wp, wp_len = wp.cuda(), wp_len.cuda()\n",
    "            ph, ph_len = ph.cuda(), ph_len.cuda()\n",
    "            mel, mel_len = mel.cuda(), mel_len.cuda()\n",
    "            wp_attn, ph_attn = wp_attn.float().cuda(), ph_attn.float().cuda() # [b, #wp, #wrds], [b, #ph, #wrds]\n",
    "\n",
    "            (z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_) = \\\n",
    "                generator(ph, ph_len, mel, mel_len, gen=False)\n",
    "\n",
    "            \n",
    "            z_bert = model(wp, ph, wp_attn, ph_attn, attn)\n",
    "            #loss = commons.mle_loss(z, z_m+z_bert, z_logs, logdet, z_mask)\n",
    "            loss = commons.mle_loss(z, z_bert, z_logs, logdet, z_mask)\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "def evaluate_control():\n",
    "    total_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (wp, wp_len, ph, ph_len, mel, mel_len, wp_attn, ph_attn) in enumerate(test_loader):\n",
    "            wp, wp_len = wp.cuda(), wp_len.cuda()\n",
    "            ph, ph_len = ph.cuda(), ph_len.cuda()\n",
    "            mel, mel_len = mel.cuda(), mel_len.cuda()\n",
    "            wp_attn, ph_attn = wp_attn.float().cuda(), ph_attn.float().cuda() # [b, #wp, #wrds], [b, #ph, #wrds]\n",
    "\n",
    "            (z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_) = \\\n",
    "                generator(ph, ph_len, mel, mel_len, gen=False)\n",
    "            \n",
    "            loss = commons.mle_loss(z, z_m, z_logs, logdet, z_mask)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8cd9094ccacc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-7fcdce087180>\u001b[0m in \u001b[0;36mevaluate_control\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogw_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/andrehe/glow-tts/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_lengths, y, y_lengths, g, gen, noise_scale, length_scale, hardcoded_durs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [b, h]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mx_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhardcoded_durs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhardcoded_durs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# we might inject LM embeddings into x_m and x_logs (logw for duration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/andrehe/glow-tts/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_lengths, g, hardcoded_durs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprenet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/andrehe/glow-tts/attentions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_mask)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/andrehe/glow-tts/attentions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_mask)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gelu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.702\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sources/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    259\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 260\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "lp = BertLinearLP(bert).cuda()\n",
    "optimizer = optim.Adam(lp.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_bert = DistilBertModel(DistilBertConfig())\n",
    "lp_control = BertLinearLP(untrained_bert).cuda()\n",
    "optimizer_control = optim.Adam(lp_control.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:25,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "112.50135899079152 55.35756988525391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:25,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "45.273293558756514 37.74071248372396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "34.37184526003324 31.00193608601888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "27.76936887105306 28.821146519978843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "23.128089875441333 18.104911677042644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:30,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "17.293062393481915 15.071093877156576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:27,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "13.650272829104692 12.762255414326985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "11.71633831048623 10.625585746765136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "9.421449625797761 8.387213675181071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:30,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "7.356309830836761 6.480639934539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "5.465555655650603 4.888082345326741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:32,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "4.120218339944497 3.7103049914042154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:30,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "3.1706073571474125 2.849638303120931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "2.418672336370517 2.1383532762527464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "1.9278725407062434 1.7124805291493734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "1.4242950277450757 1.264572258790334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:28,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "1.0909640432932437 1.0144292950630187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "0.8449336249858905 0.7829905311266582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [03:27,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "0.6927620685253388 0.6057421962420145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [02:34,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test:\n",
      "0.5186443076683924 0.451876825094223\n"
     ]
    }
   ],
   "source": [
    "log = train(20, lp, optimizer)\n",
    "log_control = train(20, lp_control, optimizer_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9bfe535d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(log_control['test'], c='r')\n",
    "plt.plot(log['test'], c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lp_control' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8413189e877e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints/latent-predictor_nn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlp_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints/latent_predictor_control'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lp_control' is not defined"
     ]
    }
   ],
   "source": [
    "lp.load_state_dict(torch.load('checkpoints/latent-predictor_nn'))\n",
    "#lp_control.load_state_dict(torch.load('checkpoints/latent_predictor_control'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054049071311950685"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(generator, model, x, x_lengths, wp, wp_attn, ph_attn, g=None):\n",
    "    noise_scale = 1.\n",
    "    length_scale = 1.\n",
    "    x_m, x_logs, logw, x_mask = generator.encoder(x, x_lengths, g=g)\n",
    "    \n",
    "    w = torch.exp(logw) * x_mask * length_scale\n",
    "    w_ceil = torch.ceil(w)\n",
    "    y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n",
    "    y_max_length = None\n",
    "    \n",
    "    y, y_lengths, y_max_length = generator.preprocess(None, y_lengths, y_max_length)\n",
    "    z_mask = torch.unsqueeze(commons.sequence_mask(y_lengths, y_max_length), 1).to(x_mask.dtype)\n",
    "    attn_mask = torch.unsqueeze(x_mask, -1) * torch.unsqueeze(z_mask, 2)\n",
    "    \n",
    "    attn = commons.generate_path(w_ceil.squeeze(1), attn_mask.squeeze(1)).unsqueeze(1)\n",
    "    # z_m = torch.matmul(attn.squeeze(1).transpose(1, 2), x_m.transpose(1, 2)).transpose(1, 2) # [b, t', t], [b, t, d] -> [b, d, t']\n",
    "    z_logs = torch.matmul(attn.squeeze(1).transpose(1, 2), x_logs.transpose(1, 2)).transpose(1, 2) # [b, t', t], [b, t, d] -> [b, d, t']\n",
    "    logw_ = torch.log(1e-8 + torch.sum(attn, -1)) * x_mask\n",
    "    \n",
    "    z_bert = model(wp, x, wp_attn, ph_attn, attn)\n",
    "    \n",
    "    z = (z_bert + torch.exp(z_logs) * torch.randn_like(z_bert) * noise_scale) * z_mask\n",
    "    \n",
    "    y, logdet = generator.decoder(z, z_mask, g=g, reverse=True)\n",
    "    return (y, z_bert, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (wp, wp_len, ph, ph_len, mel, mel_len, wp_attn, ph_attn) in enumerate(train_loader):\n",
    "        wp, wp_len = wp.cuda(), wp_len.cuda()\n",
    "        ph, ph_len = ph.cuda(), ph_len.cuda()\n",
    "        mel, mel_len = mel.cuda(), mel_len.cuda()\n",
    "        wp_attn, ph_attn = wp_attn.float().cuda(), ph_attn.float().cuda() # [b, #wp, #wrds], [b, #ph, #wrds]\n",
    "\n",
    "\n",
    "        (y, *_), *_, (attn, logw, _) = infer(generator, lp, ph, ph_len, wp, wp_attn, ph_attn)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
